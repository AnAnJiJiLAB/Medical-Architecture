{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "import math as math\n",
    "import pywt as pywt\n",
    "import random\n",
    "import h5py\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from sklearn.externals import joblib\n",
    "from scipy import signal\n",
    "from keras.utils import np_utils\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "from scipy.signal import medfilt\n",
    "from IPython.display import display\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Flatten,Conv2D,MaxPooling2D,Conv1D,MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 3, 28, 24, 13, 14, 32, 42, 25, 38, 12, 39, 19, 16, 7, 40, 6, 15, 31, 34, 27, 22, 1, 9, 17, 10, 23, 29, 26, 2, 8, 20, 5, 35, 4, 18, 0, 37, 33, 36, 21, 41, 11] -----files_1\n",
      "['patient096_s0381lre.csv', 'patient038_s0125lre.csv', 'patient094_s0412lre.csv', 'patient076_s0319lre.csv', 'patient069_s0232lre.csv', 'patient069_s0233lre.csv', 'patient096_s0395lre.csv', 'patient293_s0558_re.csv', 'patient094_s0368lre.csv', 'patient270_s0507_re.csv', 'patient068_s0228lre.csv', 'patient292_s0555_re.csv', 'patient073_s0249lre.csv', 'patient069_s0284lre.csv', 'patient048_s0172lre.csv', 'patient292_s0556_re.csv', 'patient048_s0171lre.csv', 'patient069_s0234lre.csv', 'patient096_s0385lre.csv', 'patient099_s0388lre.csv', 'patient094_s0376lre.csv', 'patient076_s0250lre.csv', 'patient027_s0096lre.csv', 'patient048_s0277lre.csv', 'patient073_s0238lre.csv', 'patient062_s0212lre.csv', 'patient076_s0253lre.csv', 'patient096_s0379lre.csv', 'patient094_s0370lre.csv', 'patient027_s0151lre.csv', 'patient048_s0180lre.csv', 'patient073_s0252lre.csv', 'patient038_s0162lre.csv', 'patient099_s0397lre.csv', 'patient038_s0128lre.csv', 'patient073_s0243lre.csv', 'patient027_s0089lre.csv', 'patient265_s0501_re.csv', 'patient099_s0387lre.csv', 'patient099_s0419lre.csv', 'patient076_s0247lre.csv', 'patient293_s0557_re.csv', 'patient063_s0214lre.csv'] ---- n_list\n",
      "(0,)\n",
      "0\n",
      "(1, 24000)\n",
      "0\n",
      "(2, 24000)\n",
      "0\n",
      "(3, 24000)\n",
      "0\n",
      "(4, 24000)\n",
      "0\n",
      "(5, 24000)\n",
      "0\n",
      "(6, 24000)\n",
      "0\n",
      "(7, 24000)\n",
      "0\n",
      "(8, 24000)\n",
      "0\n",
      "(9, 24000)\n",
      "0\n",
      "(10, 24000)\n",
      "0\n",
      "(11, 24000)\n",
      "0\n",
      "(12, 24000)\n",
      "0\n",
      "(13, 24000)\n",
      "0\n",
      "(14, 24000)\n",
      "0\n",
      "(15, 24000)\n",
      "0\n",
      "(16, 24000)\n",
      "0\n",
      "(17, 24000)\n",
      "0\n",
      "(18, 24000)\n",
      "0\n",
      "(19, 24000)\n",
      "0\n",
      "(20, 24000)\n",
      "0\n",
      "(21, 24000)\n",
      "0\n",
      "(22, 24000)\n",
      "0\n",
      "(23, 24000)\n",
      "0\n",
      "(24, 24000)\n",
      "0\n",
      "(25, 24000)\n",
      "0\n",
      "(26, 24000)\n",
      "0\n",
      "(27, 24000)\n",
      "0\n",
      "(28, 24000)\n",
      "0\n",
      "(29, 24000)\n",
      "0\n",
      "(30, 24000)\n",
      "0\n",
      "(31, 24000)\n",
      "0\n",
      "(32, 24000)\n",
      "0\n",
      "(33, 24000)\n",
      "0\n",
      "(34, 24000)\n",
      "0\n",
      "(35, 24000)\n",
      "0\n",
      "(36, 24000)\n",
      "0\n",
      "(37, 24000)\n",
      "0\n",
      "(38, 24000)\n",
      "0\n",
      "(39, 24000)\n",
      "0\n",
      "(40, 24000)\n",
      "0\n",
      "(41, 24000)\n",
      "0\n",
      "(42, 24000)\n",
      "0\n",
      "[18, 59, 8, 9, 38, 32, 48, 69, 10, 6, 25, 33, 13, 19, 51, 29, 31, 56, 39, 66, 22, 3, 14, 34, 23, 11, 26, 50, 20, 72, 41, 53, 52, 17, 68, 63, 40, 46, 12, 60, 37, 21, 44] -----files_1\n",
      "['patient173_s0305lre.csv', 'patient251_s0506_re.csv', 'patient150_s0287lre.csv', 'patient155_s0301lre.csv', 'patient233_s0483_re.csv', 'patient229_s0452_re.csv', 'patient241_s0470_re.csv', 'patient279_s0531_re.csv', 'patient156_s0299lre.csv', 'patient122_s0312lre.csv', 'patient180_s0545_re.csv', 'patient229_s0453_re.csv', 'patient166_s0275lre.csv', 'patient174_s0300lre.csv', 'patient244_s0473_re.csv', 'patient185_s0336lre.csv', 'patient214_s0436_re.csv', 'patient248_s0481_re.csv', 'patient234_s0460_re.csv', 'patient267_s0504_re.csv', 'patient180_s0476_re.csv', 'patient117_s0291lre.csv', 'patient169_s0328lre.csv', 'patient233_s0457_re.csv', 'patient180_s0477_re.csv', 'patient165_s0322lre.csv', 'patient180_s0561_re.csv', 'patient243_s0472_re.csv', 'patient180_s0374lre.csv', 'patient284_s0552_re.csv', 'patient236_s0462_re.csv', 'patient245_s0480_re.csv', 'patient245_s0474_re.csv', 'patient172_s0304lre.csv', 'patient277_s0527_re.csv', 'patient263_s0499_re.csv', 'patient235_s0461_re.csv', 'patient239_s0467_re.csv', 'patient165_s0323lre.csv', 'patient252_s0487_re.csv', 'patient233_s0482_re.csv', 'patient180_s0475_re.csv', 'patient237_s0465_re.csv'] ---- n_list\n",
      "(43, 24000)\n",
      "1\n",
      "(44, 24000)\n",
      "1\n",
      "(45, 24000)\n",
      "1\n",
      "(46, 24000)\n",
      "1\n",
      "(47, 24000)\n",
      "1\n",
      "(48, 24000)\n",
      "1\n",
      "(49, 24000)\n",
      "1\n",
      "(50, 24000)\n",
      "1\n",
      "(51, 24000)\n",
      "1\n",
      "(52, 24000)\n",
      "1\n",
      "(53, 24000)\n",
      "1\n",
      "(54, 24000)\n",
      "1\n",
      "(55, 24000)\n",
      "1\n",
      "(56, 24000)\n",
      "1\n",
      "(57, 24000)\n",
      "1\n",
      "(58, 24000)\n",
      "1\n",
      "(59, 24000)\n",
      "1\n",
      "(60, 24000)\n",
      "1\n",
      "(61, 24000)\n",
      "1\n",
      "(62, 24000)\n",
      "1\n",
      "(63, 24000)\n",
      "1\n",
      "(64, 24000)\n",
      "1\n",
      "(65, 24000)\n",
      "1\n",
      "(66, 24000)\n",
      "1\n",
      "(67, 24000)\n",
      "1\n",
      "(68, 24000)\n",
      "1\n",
      "(69, 24000)\n",
      "1\n",
      "(70, 24000)\n",
      "1\n",
      "(71, 24000)\n",
      "1\n",
      "(72, 24000)\n",
      "1\n",
      "(73, 24000)\n",
      "1\n",
      "(74, 24000)\n",
      "1\n",
      "(75, 24000)\n",
      "1\n",
      "(76, 24000)\n",
      "1\n",
      "(77, 24000)\n",
      "1\n",
      "(78, 24000)\n",
      "1\n",
      "(79, 24000)\n",
      "1\n",
      "(80, 24000)\n",
      "1\n",
      "(81, 24000)\n",
      "1\n",
      "(82, 24000)\n",
      "1\n",
      "(83, 24000)\n",
      "1\n",
      "(84, 24000)\n",
      "1\n",
      "(85, 24000)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#----轉換過的ECG list\n",
    "label = []\n",
    "all_ecg = []\n",
    "Sucess = 0\n",
    "conb_train = []\n",
    "conb_train_label = []\n",
    "conb_test = []\n",
    "conb_test_label = []\n",
    "#------------\n",
    "f_list = [] \n",
    "#n_list = []\n",
    "a_mypath = [] \n",
    "\n",
    "mypath = \"ecg_data/Symptoms\"\n",
    "# 取得所有檔案與子目錄名稱\n",
    "files = listdir(mypath)\n",
    "# 以迴圈處理\n",
    "for f in files:\n",
    "  # 產生檔案的絕對路徑\n",
    "  fullpath = join(mypath, f)\n",
    "  # 判斷 fullpath 是檔案還是目錄\n",
    "  if isdir(fullpath):\n",
    "    f_list.append(f)\n",
    "#print(f_list)\n",
    "##--------------------------------------------------------------\n",
    "for i in range(0,len(f_list)):\n",
    "    mypath = \"ecg_data/Symptoms/\"+f_list[i]+\"/\"  \n",
    "    a_mypath.append(mypath)  #路徑陣列\n",
    "    n_list = []\n",
    "    files = listdir(mypath)\n",
    "    files_1 = random.sample(range(len(files)),43)\n",
    "    print(files_1,'-----files_1')\n",
    "    \n",
    "    for r in range(0,len(files_1)):\n",
    "\n",
    "        n_list.append(files[files_1[r]]) #檔名陣列\n",
    "    \n",
    "    print(n_list,\"---- n_list\")\n",
    "    \n",
    "   #print(n_list[i]) # 抓出值[][]\n",
    "    for e in range(0,len(n_list)):\n",
    "            #print(n_list[i],'-----999')\n",
    "            all_df = pd.read_csv(a_mypath[i]+n_list[e], error_bad_lines=False,low_memory=False, dtype='object')\n",
    "           \n",
    "            #print(all_df)\n",
    "            cols = [\"'i'\",\"'ii'\",\"'iii'\",\"'avr'\",\"'avl'\",\"'avf'\",\"'v1'\",\"'v2'\",\"'v3'\",\"'v4'\",\"'v5'\",\"'v6'\"]    #取得需要的欄位\n",
    "            #cols = [\"'i'\",\"'iii'\",\"'avl'\",\"'v1'\",\"'v2'\",\"'v3'\",\"'v5'\",\"'v6'\"] \n",
    "            all_df = all_df[cols][1:].astype(str).astype(float) # 把所有需要欄位+到all_df變數 和 轉型態\n",
    "            ndarray = all_df.values\n",
    "            if(len(ndarray)!=60000):   \n",
    "                print(n_list[e]+ \"---------------------------------Part1 -not 60000 fail\")\n",
    "                continue\n",
    "            else:\n",
    "                #print(n_list[e],'---555')\n",
    "                ndarray=ndarray[:].transpose()\n",
    "                #print(\"---------------------------------Part1 - Sucess\")\n",
    "            t_ecg = []\n",
    "            for num in range(0,len(ndarray)):\n",
    "                fs = 250\n",
    "                ecg = np.ravel(ndarray[num])\n",
    "                #---\n",
    "                buffer_plot =[]\n",
    "                #buffer_long=[]; \n",
    "                state = 0 \n",
    "                buffer_base=[]\n",
    "                window = round(fs/25)\n",
    "                #------------\n",
    "                ecg = ecg[:]\n",
    "                ecg_raw =ecg\n",
    "                f1=0.5\n",
    "                f2=45\n",
    "                Wn=np.array([f1,f2])*1/fs\n",
    "                N = 3\n",
    "                a,b = signal.butter(N,Wn, 'bandpass') \n",
    "                ecg = signal.filtfilt(a,b,ecg)\n",
    "                ecg=signal.resample(ecg, 2000, t=None, axis=0, window=None)\n",
    "                t_ecg.append(ecg)\n",
    "                if(f_list[i] == \"antero-lateral\"):\n",
    "                    Symptoms = 0\n",
    "                if(f_list[i] == \"health4\"):\n",
    "                    Symptoms = 1 \n",
    "                '''\n",
    "                if(f_list[i] == \"infero-lateral\"):\n",
    "                    Symptoms = 0\n",
    "\n",
    "                if(f_list[i] == \"Health\"):\n",
    "                    Symptoms = 1 \n",
    "                \n",
    "                \n",
    "                    \n",
    "                if(f_list[i] == \"infero-lateral\"):\n",
    "                    Symptoms = 1\n",
    "                    \n",
    "                \n",
    "                     \n",
    "                    \n",
    "                if(f_list[i] == \"anterior\"):\n",
    "                    Symptoms = 0 \n",
    "                 \n",
    "                if(f_list[i] == \"antero-septal\"):\n",
    "                    Symptoms = 0\n",
    "                \n",
    "                    \n",
    "                \n",
    "                '''\n",
    "         \n",
    "            print(np.asarray(all_ecg).shape)# 每一筆12 leads心電圖 , 720000(60000*12)\n",
    "            \n",
    "            all_ecg.append(np.ravel(t_ecg).T)\n",
    "            label.append(np.ravel(Symptoms))\n",
    "            \n",
    "            print(Symptoms)\n",
    "        \n",
    "           \n",
    "            \n",
    "            #plt.figure(figsize=(17, 4)) #圖的大小\n",
    "            #plt.plot(t_I)\n",
    "            #plt.show()\n",
    "            \n",
    "            #print(\"---------------------------------Part2 - Sucess\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 33\n",
      "43 76\n",
      "(2, 33, 24000) (2, 33, 1)\n",
      "(2, 9, 24000) (2, 9, 1)\n"
     ]
    }
   ],
   "source": [
    "train_Data = []\n",
    "train_label= []\n",
    "test_Data= []\n",
    "test_label= []\n",
    "\n",
    "step = 0\n",
    "step_end= 33 #32/ 57\n",
    "for g in range(0,2): \n",
    "  \n",
    "    train_Data.append(np.asarray(all_ecg[step:step_end]))\n",
    "    train_label.append(np.asarray(label[step:step_end]))\n",
    "    \n",
    "    test_Data.append(np.asarray(all_ecg[step_end:step_end+9]))\n",
    "    test_label.append(np.asarray(label[step_end:step_end+9]))\n",
    "\n",
    "    print(step,step_end)\n",
    "    step = step+43\n",
    "    step_end = step_end+43\n",
    "\n",
    "\n",
    "print(np.asarray(train_Data).shape,np.asarray(train_label).shape)\n",
    "print(np.asarray(test_Data).shape,np.asarray(test_label).shape)\n",
    "\n",
    "#print(np.asarray(train_label))\n",
    "\n",
    "#(64,60000) (64,1)\n",
    "#(16,60000) (16,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 24000)\n",
      "(18, 24000)\n"
     ]
    }
   ],
   "source": [
    "train_Data,train_label = np.asarray(train_Data), np.asarray(train_label)\n",
    "test_Data,test_label = np.asarray(test_Data), np.asarray(test_label)\n",
    "\n",
    "train_Data = train_Data.reshape(66,24000).astype('float32')#720000\n",
    "test_Data = test_Data.reshape(18,24000).astype('float32')\n",
    "\n",
    "# 歸一化\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_train_Data = scaler.fit_transform(train_Data)\n",
    "scaled_test_Data = scaler.fit_transform(test_Data)\n",
    "\n",
    "print(scaled_train_Data.shape)\n",
    "print(scaled_test_Data.shape)\n",
    "\n",
    "reshape_scaled_train_Data =scaled_train_Data.reshape(scaled_train_Data.shape[0],24000,1).astype('float32')#720000\n",
    "reshape_scaled_test_Data =scaled_test_Data.reshape(scaled_test_Data.shape[0],24000,1).astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "y_TrainOneHot = np_utils.to_categorical(np.ravel(train_label))\n",
    "y_TestOneHot = np_utils.to_categorical(np.ravel(test_label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 24000, 1)\n",
      "(66, 2)\n",
      "(18, 24000, 1)\n",
      "(18, 2)\n"
     ]
    }
   ],
   "source": [
    "#訓練Data和label\n",
    "print(reshape_scaled_train_Data.shape)\n",
    "#print(y_TrainOneHot)\n",
    "print(y_TrainOneHot.shape)\n",
    "\n",
    "#測試Data和label\n",
    "print(reshape_scaled_test_Data.shape)\n",
    "#print(y_TestOneHot)\n",
    "print(y_TestOneHot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#720000\n",
    "model.add(Conv1D(filters=16,\n",
    "                 kernel_size=(25),\n",
    "                 padding='same',\n",
    "                 input_shape=(24000,1), \n",
    "                 activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(MaxPooling1D(pool_size=(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv1D(filters=36,\n",
    "                 kernel_size=(25),\n",
    "                 padding='same',\n",
    "                 activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(MaxPooling1D(pool_size=(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 24000, 16)         416       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 6000, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 6000, 36)          14436     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1500, 36)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1500, 36)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 54000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               6912128   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 6,927,238\n",
      "Trainable params: 6,927,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52 samples, validate on 14 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "# 1100- 20 -0.75\n",
    "# 1200- 20 -0.8125\n",
    "# 1200- 30 -0.8125\n",
    "# 1200- 40 -0.8125\n",
    "# 1200- 70 -0.8125\n",
    "# 1200- 80 -0.8125\n",
    "# 1200- 90 -0.8125\n",
    "# 1200- 100 -0.8125\n",
    "# 1500 - 100 -0.9375\n",
    "# 1600 - 100 -0.9375\n",
    "# 2000 - 100 - 0.9375 圖很好看\n",
    "train_history=model.fit(x=reshape_scaled_train_Data, \n",
    "                        y=y_TrainOneHot,\n",
    "                        validation_split=0.2, \n",
    "                        epochs=100, \n",
    "                        batch_size=300,\n",
    "                        verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_train_history(train_acc,test_acc):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(train_history.history[train_acc])\n",
    "    plt.plot(train_history.history[test_acc])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_train_history('acc','val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_train_history('loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(reshape_scaled_test_Data,y_TestOneHot)\n",
    "print(scores[0],scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_classes(reshape_scaled_test_Data,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save('Save_modle/antero-lateral/antero-lateral2/model_infero-lateral_1_0.94.h5')  \n",
    "\n",
    "#del model\n",
    "#model = load_model('Save_modle/model_antero-lateral_.h5')\n",
    "#scores = model.evaluate(reshape_scaled_test_Data , y_TestOneHot)\n",
    "#print(scores[0],scores[1])\n",
    "#prediction = model.predict_classes(reshape_scaled_test_Data)\n",
    "#prediction[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#proba = model.predict_proba(reshape_scaled_test_Data)\n",
    "#print(proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
